{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Exp2 Morphology Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2l8SfYg91ABQdsMK5gU2X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhargav-joshi/NLP-Practicals/blob/main/NLP_Exp2_Morphology_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t4qxLxnDk0kw",
        "outputId": "23f4c30c-56ff-4ae8-9947-8245556e9373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "WordList:  ['I', 'visited', 'college', 'today', 'for', 'collecting', 'my', 'result', 'It', 'is', 'available', 'at', 'the', 'computer', 'department']\n",
            "\n",
            "Porter Stemmer\n",
            "I\n",
            "visit\n",
            "colleg\n",
            "today\n",
            "for\n",
            "collect\n",
            "my\n",
            "result\n",
            "It\n",
            "is\n",
            "avail\n",
            "at\n",
            "the\n",
            "comput\n",
            "depart\n",
            "\n",
            "Lancaster Stemmer\n",
            "i\n",
            "visit\n",
            "colleg\n",
            "today\n",
            "for\n",
            "collect\n",
            "my\n",
            "result\n",
            "it\n",
            "is\n",
            "avail\n",
            "at\n",
            "the\n",
            "comput\n",
            "depart\n",
            "\n",
            "Word: I\n",
            "Gender: F\n",
            "POS: Possessive Pronoun\n",
            "\n",
            "Word: visited\n",
            "Gender: M\n",
            "POS: Verb\n",
            "\n",
            "Word: college\n",
            "Gender: F\n",
            "POS: Noun Singular\n",
            "\n",
            "Word: today\n",
            "Gender: F\n",
            "POS: Noun Singular\n",
            "\n",
            "Word: for\n",
            "Gender: M\n",
            "POS: Preposition/Subordinating Conjunction\n",
            "\n",
            "Word: collecting\n",
            "Gender: M\n",
            "POS: Verb, gerund or present participle\n",
            "\n",
            "Word: my\n",
            "Gender: F\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a46ad527604a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nWord:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwordList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gender:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POS:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnamepos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-a46ad527604a>\u001b[0m in \u001b[0;36mnamepos\u001b[0;34m(pos)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlancaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnamepos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mposdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgender_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'last_letter'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'PRP$'"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import random\n",
        "nltk.download('names')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import names\n",
        "import nltk\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "mystr = 'I visited college today for collecting my result. It is available at the computer department.'\n",
        "wordList = re.sub(\"[^\\w]\", \" \", mystr).split()\n",
        "print(\"WordList: \",wordList)\n",
        "posdict = {\"PRP\":\"Possessive Pronoun\",\"NNP\":\"Proper Noun\",\"VBD\":\"Verb\",\"IN\":\"Preposition/Subordinating Conjunction\",\"NNS\":\"Noun Plural\",\"NN\":\"Noun Singular\",\"DT\":\"Determiner\",\"EX\":\"Existential there\",\"VBP\":\"Non-3rd person singular present\",\"WRB\":\"Wh-Adverb\",\"RB\":\"Adverb\",\"VB\":\"Base form\",\"VBZ\":\"Verb, 3rd person singular present\",\"VBG\":\"Verb, gerund or present participle\"}\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "print(\"\\nPorter Stemmer\")\n",
        "for i in range(len(wordList)):\n",
        "    print(porter.stem(wordList[i]))\n",
        "print(\"\\nLancaster Stemmer\")\n",
        "for i in range(len(wordList)):\n",
        "    print(lancaster.stem(wordList[i]))\n",
        "def namepos(pos):\n",
        "  return posdict[pos]\n",
        "def gender_features(word):\n",
        "  return {'last_letter':word[-1]}\n",
        "    \n",
        "labeled_names = ([(name, 'M') for name in names.words('male.txt')]+[(name, 'F') for name in names.words('female.txt')])\n",
        "random.shuffle(labeled_names)\n",
        "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
        "train_set, test_set = featuresets[500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "pos = nltk.pos_tag(wordList)\n",
        "for i in range(len(wordList)):\n",
        "    print(\"\\nWord:\",wordList[i])\n",
        "    print(\"Gender:\",classifier.classify(gender_features(wordList[i])))\n",
        "    print(\"POS:\",namepos(pos[i][1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XRbFf9FCk4FR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}